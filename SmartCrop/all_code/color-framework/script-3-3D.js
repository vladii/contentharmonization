// Run this script: node script-3-3D.js image_path=\"Image_1.bmp\" text=\"VladIonescu\" font=\"OpenSans-Regular.ttf\" font_size=50 pos_x=250 pos_y=250
// Note: it requires node.js and conventjs installed (npm install convnetjs).

var convnetjs = require('convnetjs');
var fs = require('fs');
var exec = require('child_process').exec;

var TRAIN_NEURAL_NETWORK = false;    // false here if the neural network is already trained and you want to load it from the file below.
var DUMP_FILE_NEURAL_NETWORK = "trained_neural_network.txt";    // Path to a file which contains trained neural network json.
var PREDICTIONS_ENABLED = true;    // true here if you want to do predictions (as command line arguments).
    
// Trained data (manual, by designers)
// H1,S1,B1,H2,S2,B2,H3,S3,B3,Hres,Sres,Bres
pre_trained_data = [
            0.5,0.023529412,1.0,0.5822222,0.9375,0.627451,0.12878788,0.8224299,0.8392157,0.5,1.0,0.2,
            0.54784685,0.9858491,0.83137256,0.011494249,0.22834645,0.99607843,0.7132132,0.45306122,0.9607843,0.0,0.0,0.0,
            0.957483,0.4516129,0.8509804,0.3765432,0.19148937,0.5529412,0.12820514,0.13,0.39215687,0.16666667,0.2,1.0,
            0.45238093,0.96428573,0.76862746,0.78911567,0.28994083,0.6627451,0.8117284,0.87096775,0.4862745,0.16666667,0.2,1.0,
            0.97792494,0.608871,0.972549,0.6951754,0.93442625,0.95686275,0.7351598,0.85882354,1.0,0.16666667,0.2,1.0,
            0.6260163,0.5418502,0.8901961,0.69612795,0.7826087,0.99215686,0.40034366,0.59876543,0.63529414,0.0,0.0,1.0,
            0.36111113,0.4811321,0.83137256,0.0059171617,0.91351354,0.7254902,0.42090395,0.23228346,0.99607843,0.0,0.0,0.0,
            0.4919355,0.561086,0.8666667,0.9218107,0.72,0.88235295,0.64625853,0.6805556,0.84705883,0.0,0.0,0.0,
            0.044047624,0.6392694,0.85882354,0.125,0.29787233,0.7372549,0.7670765,0.95686275,1.0,0.15500686,0.9529412,1.0,
            0.6413043,0.5411765,1.0,0.65625,0.18604651,0.3372549,0.043568462,0.98770493,0.95686275,0.15500686,0.9529412,1.0,
            0.72556394,0.8807947,0.5921569,0.8320513,0.60747665,0.8392157,0.48192772,0.80582523,0.40392157,0.15500686,0.9529412,1.0,
            0.7363184,0.6979167,0.7529412,0.16811593,0.5897436,0.7647059,0.96515155,0.7284768,0.5921569,0.0,0.0,1.0,
            0.960356,0.80784315,1.0,0.047961634,0.9858156,0.5529412,0.37434554,0.77327937,0.96862745,0.0,0.0,0.0,
            0.9224138,0.68235296,1.0,0.88271606,0.44751382,0.70980394,0.07843137,0.93292683,0.6431373,0.2820513,0.6627451,1.0,
            0.7757936,0.37004405,0.8901961,0.5833333,0.5576923,0.8156863,0.12704918,0.7672956,0.62352943,0.0,0.0,1.0,
            0.29669032,0.8867925,0.62352943,0.6333334,0.64935064,0.6039216,0.8487395,0.5833333,0.8,0.0,0.0,1.0,
            0.059848487,0.9128631,0.94509804,0.09433963,0.20866142,0.99607843,0.33542976,0.9085714,0.6862745,0.0,0.0,0.0,
            0.88095236,0.13793103,0.79607844,0.53666663,0.84033614,0.46666667,0.510989,0.59477127,0.6,0.33333334,0.27385893,0.94509804,
            0.6130952,0.34146342,0.32156864,0.51304346,0.5502392,0.81960785,0.036723167,0.9593496,0.9647059,0.16666667,0.2,1.0,
            0.7982026,0.94009215,0.8509804,0.080000006,0.92105263,0.74509805,0.910461,0.78333336,0.9411765,0.0,0.0,1.0,
            0.21676302,0.92021275,0.7372549,0.35007277,0.9346939,0.9607843,0.26237622,0.43913043,0.9019608,0.0,1.0,0.6,
            0.8396226,0.9724771,0.42745098,0.42166665,0.46948355,0.8352941,0.045871556,0.9688889,0.88235295,0.0,0.0,1.0,
            0.5131579,0.6333333,0.23529412,0.03961749,0.49392712,0.96862745,0.54432625,0.77366257,0.9529412,0.0,0.0,1.0,
            0.6678744,0.57024795,0.9490196,0.22560973,0.4039409,0.79607844,0.6642336,0.74054056,0.7254902,0.0,0.0,1.0,
            0.42045453,0.64705884,0.53333336,0.37055016,0.80784315,1.0,0.77136755,0.718894,0.8509804,0.16,0.98039216,0.2,
            0.47284642,1.0,0.69803923,0.4599156,0.6502058,0.9529412,0.07544582,0.9529412,1.0,0.16,0.98039216,0.2,
            0.58608055,0.49726775,0.7176471,0.30952382,0.20114942,0.68235296,0.46560848,0.3539326,0.69803923,0.0,0.0,1.0,
            0.0063694217,0.84408605,0.7294118,0.77973574,0.8901961,1.0,0.6666667,0.5622318,0.9137255,0.0,0.0,1.0,
            0.15600775,0.7962963,0.84705883,0.06706115,0.8325123,0.79607844,0.8604651,0.699187,0.9647059,0.0,0.0,0.0,
            0.817029,0.5786164,0.62352943,0.16300367,0.51704544,0.6901961,0.7160494,0.46153846,0.45882353,0.0,0.0,1.0,
            0.5254453,0.58744395,0.8745098,0.48684213,0.29803923,1.0,0.34908137,0.51209676,0.972549,0.0,0.0,0.0,
            0.3196347,0.7373737,0.3882353,0.029891303,0.855814,0.84313726,0.25,0.21621622,0.2901961,0.0,0.0,1.0,
            0.9336158,0.9672131,0.47843137,0.9277389,0.60084033,0.93333334,0.7829861,0.7058824,0.53333336,0.0,0.0,1.0,
            0.87099814,0.74058574,0.9372549,0.29038855,0.77619046,0.8235294,0.393018,0.69158876,0.8392157,0.0,0.0,0.0,
            0.21439393,0.8627451,1.0,0.05454545,0.22540984,0.95686275,0.594697,0.7719298,0.89411765,0.0,0.0,0.0,
            0.095776774,0.96086955,0.9019608,0.61515146,0.52884614,0.40784314,0.2601626,0.73214287,0.4392157,0.0,0.0,1.0,
            0.92168677,0.5608108,0.5803922,0.2960426,0.897541,0.95686275,0.48765433,0.13705584,0.77254903,0.0,0.0,0.0,
            0.047222227,0.6666667,0.3529412,0.9627193,0.3275862,0.9098039,0.14054054,0.9536083,0.7607843,0.0,0.0,1.0,
            0.26666665,0.9876543,0.31764707,0.5276008,0.8306878,0.7411765,0.7022059,0.6666667,0.8,0.0,0.0,1.0,
            0.95772946,0.6272727,0.8627451,0.89312977,0.58744395,0.8745098,0.100187264,0.98342544,0.70980394,0.72222227,1.0,0.6,
            0.8469388,0.40163934,0.95686275,0.0925926,0.8117647,1.0,0.97619045,0.875,0.4392157,0.32312927,0.3740458,0.5137255,
            0.093495935,0.38497654,0.8352941,0.84632033,0.64166665,0.47058824,0.87608695,0.9019608,1.0,0.0,0.0,1.0,
            0.96907216,0.6643836,0.57254905,0.4417863,0.9008621,0.9098039,0.41773507,0.6117647,1.0,0.0,0.0,0.0,
            0.5989583,0.1322314,0.9490196,0.250646,0.92142856,0.54901963,0.32777777,1.0,0.7058824,0.023809522,0.79545456,0.34509805,
            0.62792796,0.8008658,0.90588236,0.4191033,0.6785714,0.9882353,0.89312977,0.5720524,0.8980392,0.0,0.0,0.0,
            0.40123454,0.23684211,0.44705883,0.30512822,0.2631579,0.96862745,0.8830409,0.9144385,0.73333335,0.0,0.0,0.0,
            0.71495324,1.0,0.41960785,0.6316348,0.8306878,0.7411765,0.33675215,0.8227848,0.92941177,0.0,0.0,1.0,
            0.8462783,0.9951691,0.8117647,0.5696203,0.48765433,0.63529414,0.53391474,0.7818182,0.8627451,0.0,0.0,1.0,
            0.37,0.44444445,0.88235295,0.83830845,0.45578232,0.5764706,0.9386667,0.9469697,0.5176471,0.0,0.0,1.0,
            0.746085,0.61570245,0.9490196,0.88461536,0.5064935,0.6039216,0.99415207,0.35185185,0.63529414,0.0,0.0,1.0,
            0.6261261,0.63247865,0.45882353,0.41078433,0.7296137,0.9137255,0.069069065,0.87058824,1.0,0.15749235,0.42745098,1.0,
            0.7369478,0.33333334,0.9764706,0.07857143,0.47619048,0.5764706,0.5416667,0.032258064,0.972549,0.0,0.0,0.0,
            0.2541667,0.25641027,0.6117647,0.40789473,0.31932774,0.93333334,0.07539683,0.16470589,1.0,0.0,0.0,0.0,
            0.075231485,0.5647059,1.0,0.8595601,0.9336493,0.827451,0.2109375,1.0,0.7529412,0.6158536,1.0,0.32156864,
            0.39065817,0.6356275,0.96862745,0.32978725,0.6878049,0.8039216,0.013157894,0.35185185,0.84705883,0.6158536,1.0,0.32156864,
            0.92105263,0.65841585,0.7921569,0.76158446,0.902834,0.96862745,0.16292974,0.9291667,0.9411765,0.6666667,0.974359,0.30588236,
            0.6904762,0.6542056,0.41960785,0.92857146,0.69135803,0.9529412,0.52642274,0.92655367,0.69411767,0.0,0.0,1.0,
            0.5840841,0.87058824,1.0,0.5490196,1.0,1.0,0.006250004,0.3508772,0.89411765,0.14539008,0.1910569,0.9647059,
            0.77272725,0.69756097,0.8039216,0.3346561,0.49411765,1.0,0.14194916,0.9254902,1.0,0.0,0.0,0.0,
            0.6859756,0.8367347,0.76862746,0.0380117,0.8769231,0.7647059,0.69623655,0.7294118,1.0,0.0,0.0,1.0,
            0.22868216,0.5489362,0.92156863,0.7171717,0.5322581,0.24313726,0.26296297,0.5,0.7058824,0.041666668,0.90140843,0.8352941,
            0.053191494,0.9873949,0.93333334,0.5892473,0.92261904,0.65882355,0.024224808,0.81904763,0.8235294,0.0,0.0,1.0,
            0.41619048,0.71428573,0.9607843,0.19292235,0.77248675,0.7411765,0.8333333,0.40127388,0.6156863,0.0,0.0,0.0,
            0.78358203,0.86451614,0.60784316,0.89942527,0.6338798,0.7176471,0.5172414,0.82857144,0.54901963,0.0,0.0,1.0,
            0.8362069,0.6338798,0.7176471,0.33939394,0.7399103,0.8745098,0.2469136,1.0,0.5294118,0.0,0.0,0.0,
            0.64249367,0.5720524,0.8980392,0.28933334,0.6127451,0.8,0.9535865,0.5642857,0.54901963,0.0,0.0,1.0,
            0.44047618,0.10980392,1.0,0.15757576,0.6846473,0.94509804,0.109259255,0.39130434,0.9019608,0.0,0.0,0.0,
            0.5344828,0.24786325,0.91764706,0.6117216,0.47395834,0.7529412,0.06385282,0.77,0.78431374,0.0,0.0,0.0,
            0.77648574,0.94160587,0.5372549,0.20093457,0.80451125,0.52156866,0.60328645,0.33023256,0.84313726,0.0,0.0,1.0,
            0.059959352,0.8677249,0.7411765,0.06190476,0.81395346,0.16862746,0.48392555,0.9800995,0.7882353,0.0,0.0,1.0,
            0.45070422,0.73195875,0.38039216,0.9186992,0.8541667,0.5647059,0.6310606,0.95652175,0.9019608,0.0,0.0,1.0,
            0.5959596,0.66,0.98039216,0.078666665,0.5733945,0.85490197,0.87114197,0.9557522,0.8862745,0.0,0.0,1.0,
            0.667979,0.54741377,0.9098039,0.125,0.32,0.29411766,0.7723005,0.73195875,0.38039216,0.0,0.0,1.0,
            0.1437309,0.8449612,0.5058824,0.27469134,0.565445,0.7490196,0.9744898,0.43555555,0.88235295,0.0,0.0,1.0,
            0.8666667,0.7621951,0.6431373,0.19027777,0.9448819,0.99607843,0.36666667,0.27450982,1.0,0.19444446,1.0,0.047058824,
            0.9264368,0.66820276,0.8509804,0.3779343,0.68599033,0.8117647,0.4509044,0.6084906,0.83137256,0.0,0.0,0.0,
            0.28968254,0.35443038,0.92941177,0.83174604,0.8235294,1.0,0.58515817,0.6462264,0.83137256,0.0,0.0,0.0,
            0.44907406,0.5294118,0.53333336,0.7641509,0.5955056,0.69803923,0.8104396,0.85046726,0.8392157,0.0,0.0,1.0,
            0.53359175,0.8164557,0.61960787,0.93968254,0.76086956,0.5411765,0.86190474,0.24305555,0.5647059,0.0,0.0,1.0,
            0.59598607,0.75793654,0.9882353,0.9052133,0.8612245,0.9607843,0.772043,0.82887703,0.73333335,0.0,0.0,1.0,
            0.29607844,0.5120482,0.6509804,0.7767296,0.9464286,0.8784314,0.0,0.6793478,0.72156864,0.0,0.0,1.0,
            0.36333334,0.54347825,0.36078432,0.22362868,0.5197368,0.59607846,0.7045455,1.0,0.17254902,0.0,0.0,1.0,
            0.18550725,0.45816734,0.9843137,0.4500734,0.93801653,0.9490196,0.8378378,0.98013246,0.5921569,0.0,0.0,0.0,
            0.875731,0.4892704,0.9137255,0.8836806,0.89302325,0.84313726,0.06359649,0.43930635,0.6784314,0.0,0.0,0.0,
            0.87113404,0.38492063,0.9882353,0.502551,0.77165353,0.99607843,0.101899825,0.8539823,0.8862745,0.0,0.0,0.0,
            0.92349726,0.72908366,0.9843137,0.23796296,0.7929515,0.8901961,0.2903564,0.6489796,0.9607843,0.0,0.0,0.0,
            0.19823234,1.0,0.5176471,0.68274856,0.8636364,0.5176471,0.83492064,0.69536424,0.5921569,0.0,0.0,1.0,
            0.8076923,0.7137255,1.0,0.452,0.5656109,0.8666667,0.053264607,0.7822581,0.4862745,0.0,0.0,1.0,
            0.5360577,0.8221344,0.99215686,0.5408602,0.7673267,0.7921569,0.07417103,0.80932206,0.9254902,0.0,0.0,1.0,
            0.70697165,0.60714287,0.9882353,0.25233647,0.4331984,0.96862745,0.3319672,0.8356164,0.57254905,0.0,0.0,0.0,
            0.5087065,0.647343,0.8117647,0.7655367,0.66292137,0.69803923,0.5669935,0.7034483,0.5686275,0.0,0.0,1.0,
            0.87009805,0.8,1.0,0.0,0.73636365,0.43137255,0.39497718,0.73,0.39215687,0.0,0.0,1.0,
            0.45131087,0.69803923,1.0,0.6446541,0.5408163,0.38431373,0.8930348,0.65686274,0.4,0.058404554,0.96694213,0.9490196,
            0.31773877,0.8382353,0.8,0.5114379,0.5762712,0.69411767,0.9871795,0.65,0.39215687,0.0,0.0,1.0,
            0.20032053,0.8595041,0.4745098,0.17914832,0.8901961,1.0,0.60820246,0.8642534,0.8666667,0.0,0.0,0.0,
            0.52150536,0.3647059,1.0,0.3231552,0.7443182,0.6901961,0.39925373,0.5677966,0.9254902,0.0,0.0,0.0,
            0.03484848,0.87649405,0.9843137,0.8782051,0.47058824,0.8666667,0.47557473,0.5021645,0.90588236,0.0,0.0,0.0,
            0.8820755,0.654321,0.63529414,0.19047618,0.525,0.78431374,0.04027778,0.88235295,0.53333336,0.0,0.0,1.0,
            0.27098322,0.95862067,0.5686275,0.7467949,0.6117647,1.0,0.6466667,0.2283105,0.85882354,0.0,0.0,1.0,
            0.5336538,0.90829694,0.8980392,0.87077296,0.79310346,0.68235296,0.95253164,0.7383177,0.8392157,0.0,0.0,1.0,
            0.5908289,0.8831776,0.8392157,0.3703704,0.6573034,0.69803923,0.88988096,0.46280992,0.4745098,0.0,0.0,1.0,
            0.71839076,0.7552083,0.7529412,0.3033708,0.7574468,0.92156863,0.5217392,0.5564516,0.4862745,0.0,0.0,1.0,
            0.24242425,0.05,0.8627451,0.4863014,0.705314,0.8117647,0.40254235,0.6178011,0.7490196,0.0,0.0,0.0,
            0.15826331,0.5173913,0.9019608,0.023655912,0.8563536,0.70980394,0.11464968,0.8532609,0.72156864,0.0,0.0,0.0,
            0.56072354,0.6,0.84313726,0.88235295,0.7589286,0.4392157,0.35064936,1.0,0.90588236,0.0,0.0,1.0,
            0.6465325,0.6367521,0.91764706,0.8708514,0.90588236,1.0,0.508547,0.27272728,0.56078434,0.0,0.0,1.0,
            0.20370372,0.80597013,0.5254902,0.4482759,0.9354839,0.972549,0.6812715,0.9238095,0.8235294,0.0,0.0,1.0,
            0.36836517,0.91812867,0.67058825,0.6166666,0.5325444,0.6627451,0.5238095,0.14583333,0.1882353,0.0,0.0,1.0,
            0.9166667,0.72131145,0.7176471,0.7857143,0.1590909,0.5176471,0.6467237,0.7548387,0.60784316,0.0,0.0,1.0,
            0.67857146,0.56852794,0.77254903,0.99114335,0.98571426,0.8235294,0.7083333,0.7914438,0.73333335,0.0,0.0,1.0,
            0.16666667,0.015873017,0.24705882,0.8520924,0.95454544,0.9490196,0.15873016,0.8442211,0.78039217,0.0,0.0,1.0,
            0.29198965,0.65482235,0.77254903,0.22746332,0.7327189,0.8509804,0.73333335,0.12605043,0.46666667,0.0,0.0,0.0,
            0.09615385,0.29213482,0.69803923,0.375,0.27450982,0.8,0.33221474,0.59839356,0.9764706,0.0,0.0,0.0,
            0.4465812,1.0,0.6117647,0.5422535,0.4640523,0.6,0.57246375,0.777027,0.5803922,0.0,0.0,1.0,
            0.95726496,0.8239437,0.5568628,0.5698413,0.6104651,0.6745098,0.7383253,0.96728975,0.8392157,0.0,0.0,1.0,
            0.19217686,0.6805556,0.5647059,0.13730569,0.9061033,0.8352941,0.7635934,0.6103896,0.90588236,0.0,0.0,0.0,
            0.574187,0.9425287,0.68235296,0.81382114,0.8541667,0.9411765,0.9235474,0.8582677,0.49803922,0.0,0.0,1.0,
            0.9316436,0.97309417,0.8745098,0.75986844,0.8786127,0.6784314,0.46616542,0.6751269,0.77254903,0.0,0.0,1.0,
            0.73571426,0.7070707,0.3882353,0.0,0.6509434,0.41568628,0.042314332,0.9897436,0.7647059,0.0,0.0,1.0,
            0.4030303,0.4888889,0.88235295,0.28036177,0.6825397,0.7411765,0.4102564,0.8552632,0.89411765,0.0,0.0,0.0,
            0.9636752,0.8914286,0.6862745,0.3979592,0.765625,0.5019608,0.22997415,0.6,0.84313726,0.0,0.0,1.0,
            0.48358586,0.58666664,0.88235295,0.7125604,0.8661088,0.9372549,0.5862069,0.5272727,0.43137255,0.0,0.0,1.0,
            0.5052493,0.61650485,0.80784315,0.7025948,0.7556561,0.8666667,0.8244445,0.90909094,0.64705884,0.0,0.0,1.0,
            0.32995495,0.62184876,0.93333334,0.027027031,0.88095236,0.65882355,0.15222223,0.79787236,0.7372549,0.0,0.0,0.0,
            0.67333335,0.28089887,0.34901962,0.65891474,0.36134455,0.46666667,0.20957096,0.74814814,0.5294118,0.0,0.0,1.0,
            0.61407405,0.9,0.98039216,0.058139533,0.704918,0.23921569,0.19411767,0.52469134,0.63529414,0.0,0.0,1.0,
            0.33333334,0.05957447,0.92156863,0.63799286,0.48947367,0.74509805,0.90220386,0.61421317,0.77254903,0.0,0.0,0.0,
            0.9160998,0.7205882,0.8,0.2535461,0.49473685,0.74509805,0.071949,1.0,0.7176471,0.0,0.0,0.0,
            0.3871528,0.58536583,0.6431373,0.85333335,0.66079295,0.8901961,0.28437498,0.6896552,0.9098039,0.0,0.0,0.0,
            0.060224086,0.6165803,0.75686276,0.47126436,0.90625,0.627451,0.26937985,0.75438595,0.89411765,0.0,0.0,0.0,
            0.11643835,0.918239,0.62352943,0.44919786,0.73333335,1.0,0.8439716,0.8197674,0.6745098,0.0,0.0,0.0,
            0.3235294,0.28651685,0.69803923,0.09848485,0.6197183,0.5568628,0.38047138,0.39285713,0.9882353,0.0,0.0,0.0,
            0.33707866,0.3755274,0.92941177,0.99425286,0.453125,0.7529412,0.027426163,0.64489794,0.9607843,0.0,0.0,0.0,
            0.7826667,0.5274262,0.92941177,0.84543014,1.0,0.972549,0.41369048,0.5803109,0.75686276,0.0,0.0,1.0,
            0.657197,0.35341364,0.9764706,0.3129252,0.5697674,0.6745098,0.72035795,0.6182573,0.94509804,0.0,0.0,1.0,
            0.025862068,0.9626556,0.94509804,0.79193205,0.6624473,0.92941177,0.858156,0.43925235,0.8392157,0.0,0.0,1.0,
            0.1888889,0.36734694,0.9607843,0.7794118,0.5284974,0.75686276,0.9662813,0.6947791,0.9764706,0.0,0.0,0.0,
            0.24000001,0.42735043,0.91764706,0.7831715,0.97630334,0.827451,0.9080882,0.6834171,0.78039217,0.0,0.0,1.0,
            0.5261438,0.69863015,0.57254905,0.22123893,0.4593496,0.9647059,0.12473118,0.63786006,0.9529412,0.0,0.0,0.0,
            0.19892474,0.18235295,0.6666667,0.7590909,0.43650794,0.9882353,0.9022222,0.48387095,0.60784316,0.0,0.0,1.0,
            0.14711934,0.7902439,0.8039216,0.19362743,0.7195767,0.7411765,0.77513224,0.8008475,0.9254902,0.0,0.0,1.0,
            0.5493827,0.6585366,0.6431373,0.4125,0.43010753,0.7294118,0.53193617,0.835,0.78431374,0.0,0.0,1.0,
            0.23293173,0.35470086,0.91764706,0.01544715,0.8951965,0.8980392,0.6026201,0.9308943,0.9647059,0.0,0.0,0.0,
            0.18240742,0.8294931,0.8509804,0.42666665,0.7246377,0.8117647,0.108024694,0.45762712,0.4627451,0.0,0.0,1.0,
            0.06645569,0.6752137,0.91764706,0.7344633,0.4796748,0.48235294,0.875,0.56842107,0.74509805,0.0,0.0,1.0,
            0.41577062,0.9162561,0.79607844,0.2868217,0.6292683,0.8039216,0.55864197,0.96,0.88235295,0.0,0.0,0.0,
            0.24061811,0.65938866,0.8980392,0.9666667,0.055248618,0.70980394,0.09760589,0.95767194,0.7411765,0.0,0.0,0.0,
            0.38961038,0.7586207,0.79607844,0.8492063,0.525,0.78431374,0.03191489,0.58264464,0.9490196,0.0,0.0,0.0,
            0.32843137,0.2982456,0.89411765,0.19923373,0.34251967,0.99607843,0.96153843,0.06403941,0.79607844,0.0,0.0,0.0,
            0.021645019,0.5167785,0.58431375,0.25990096,0.81781375,0.96862745,0.26682317,0.8729508,0.95686275,0.0,0.0,0.0,
            0.937247,1.0,0.96862745,0.4097222,0.7671233,0.85882354,0.24319728,0.601227,0.6392157,0.0,0.0,0.0,
            0.76969695,0.6395349,0.6745098,0.3083333,0.95238096,0.90588236,0.067129634,0.9,0.9411765,0.0,0.0,0.0,
            0.844697,0.17254902,1.0,0.8535714,0.8,0.6862745,0.43888888,0.9411765,1.0,0.0,0.0,0.0,
            0.19517545,0.38190955,0.78039217,0.29591838,0.2139738,0.8980392,0.5307017,0.80508476,0.9254902,0.0,0.0,0.0,
            0.9587459,0.43913043,0.9019608,0.99681526,0.7072072,0.87058824,0.102713175,0.6745098,1.0,0.0,0.0,0.0,
            0.09354839,0.8857143,0.6862745,0.99856323,0.46774194,0.972549,0.93445694,0.4784946,0.7294118,0.0,0.0,0.0,
            0.7959502,0.5119617,0.81960785,0.37290168,0.6682692,0.8156863,0.13756613,0.90430623,0.81960785,0.0,0.0,0.0,
            0.9209622,0.7854251,0.96862745,0.81088084,0.8041667,0.9411765,0.6213873,0.7393162,0.91764706,0.0,0.0,1.0,
            0.77160496,0.9270386,0.9137255,0.5242718,0.75735295,0.53333336,0.077898555,0.72440946,0.99607843,0.0,0.0,1.0,
            0.25968993,0.76106197,0.8862745,0.053594768,1.0,1.0,0.46376812,0.8380567,0.96862745,0.0,0.0,0.0
];

/**
for (var i = 0; i < pre_trained_data.length; i += 12) {
    // Try all input data permutations.
    for (var t1 = 0; t1 < 3; t1++) {
        for (var t2 = 0; t2 < 3; t2++) {
            for (var t3 = 0; t3 < 3; t3++) {
                if (t1 == t2 || t2 == t3 || t3 == t1) continue;
                
                var H1 = 360 * pre_trained_data[i + t1 * 3 + 0];
                var S1 = 100 * pre_trained_data[i + t1 * 3 + 1];
                var B1 = 100 * pre_trained_data[i + t1 * 3 + 2];
                var H2 = 360 * pre_trained_data[i + t2 * 3 + 0];
                var S2 = 100 * pre_trained_data[i + t2 * 3 + 1];
                var B2 = 100 * pre_trained_data[i + t2 * 3 + 2];
                var H3 = 360 * pre_trained_data[i + t3 * 3 + 0];
                var S3 = 100 * pre_trained_data[i + t3 * 3 + 1];
                var B3 = 100 * pre_trained_data[i + t3 * 3 + 2];
                
                result = [];
                result[0] = 360 * pre_trained_data[i + 9];
                result[1] = 100 * pre_trained_data[i + 10];
                result[2] = 100 * pre_trained_data[i + 11];
                
                var color = "B";
                if (result[0] == 0 && result[1] == 0 && result[2] == 0) {
                    color = "B";
                } else if (result[2] == 100) {
                    color = "W";
                }
                
                console.log('"' + color + '"' + ", " + H1 + ", " + S1 + ", " + B1 + ", " + H2 + ", " + S2 + ", " + B2 + ", " + H3 + ", " + S3 + ", " + B3);
            }
        }
    }
}
**/

if (TRAIN_NEURAL_NETWORK) {
    var layer_defs = [];
    layer_defs.push({type:'input', out_sx:3, out_sy:1, out_depth:3});
    layer_defs.push({type:'fc', num_neurons:100, activation:'sigmoid'});
    layer_defs.push({type:'fc', num_neurons:100, activation:'sigmoid'});
    layer_defs.push({type:'fc', num_neurons:100, activation:'sigmoid'});
    layer_defs.push({type:'regression', num_neurons:3});

    var net = new convnetjs.Net();
    net.makeLayers(layer_defs);

    // Create trainer and train on given dataset.
    var trainer = new convnetjs.Trainer(net,
                                        {method: 'adadelta', l2_decay: 0.0001, batch_size: 1});

    var steps = 1000;   // Increase the number of steps if you want (perhaps?!) a better accuracy.
    while (steps >= 0) {
        steps --;
        avgloss = 0.0;

        for (var i = 0; i < pre_trained_data.length; i += 12) {
            // Try all input data permutations.
            for (var t1 = 0; t1 < 3; t1++) {
                for (var t2 = 0; t2 < 3; t2++) {
                    for (var t3 = 0; t3 < 3; t3++) {
                        if (t1 == t2 || t2 == t3 || t3 == t1) continue;
                        
                        var vol3d = new convnetjs.Vol(3, 1, 3);
                        
                        vol3d.set(0, 0, 0, 360 * pre_trained_data[i + t1 * 3 + 0]);
                        vol3d.set(0, 0, 1, 100 * pre_trained_data[i + t1 * 3 + 1]);
                        vol3d.set(0, 0, 2, 100 * pre_trained_data[i + t1 * 3 + 2]);
                        vol3d.set(1, 0, 0, 360 * pre_trained_data[i + t2 * 3 + 0]);
                        vol3d.set(1, 0, 1, 100 * pre_trained_data[i + t2 * 3 + 1]);
                        vol3d.set(1, 0, 2, 100 * pre_trained_data[i + t2 * 3 + 2]);
                        vol3d.set(2, 0, 0, 360 * pre_trained_data[i + t3 * 3 + 0]);
                        vol3d.set(2, 0, 1, 100 * pre_trained_data[i + t3 * 3 + 1]);
                        vol3d.set(2, 0, 2, 100 * pre_trained_data[i + t3 * 3 + 2]);
                        
                        result = [];
                        result[0] = 360 * pre_trained_data[i + 9];
                        result[1] = 100 * pre_trained_data[i + 10];
                        result[2] = 100 * pre_trained_data[i + 11];
                        
                        trainer.train(vol3d, result);
                        
                        avgloss += (trainer.train(vol3d, result)).loss;
                    }
                }
            }
        }
        
        console.log("[" + steps + "] Loss: " + (avgloss / (6*pre_trained_data.length/12)));
    }

    // Write trained neural network into a JSON file.
    var okSaved = fs.writeFileSync(DUMP_FILE_NEURAL_NETWORK, JSON.stringify(net.toJSON()), 'utf8');
    console.log("Trained neural network saved!");
}

// Load trained neural network from file.
var data = fs.readFileSync(DUMP_FILE_NEURAL_NETWORK, 'utf8');
trained_net = new convnetjs.Net();
trained_net.fromJSON(JSON.parse(data));

if (TRAIN_NEURAL_NETWORK) {
    // Test. Predict on given datapoints.
    for (var i = 0; i < pre_trained_data.length; i += 12) {
        var vol3d = new convnetjs.Vol(3, 1, 3);
        
        vol3d.set(0, 0, 0, 360 * pre_trained_data[i + 0]);
        vol3d.set(0, 0, 1, 100 * pre_trained_data[i + 1]);
        vol3d.set(0, 0, 2, 100 * pre_trained_data[i + 2]);
        vol3d.set(1, 0, 0, 360 * pre_trained_data[i + 3]);
        vol3d.set(1, 0, 1, 100 * pre_trained_data[i + 4]);
        vol3d.set(1, 0, 2, 100 * pre_trained_data[i + 5]);
        vol3d.set(2, 0, 0, 360 * pre_trained_data[i + 6]);
        vol3d.set(2, 0, 1, 100 * pre_trained_data[i + 7]);
        vol3d.set(2, 0, 2, 100 * pre_trained_data[i + 8]);
        
        var predicted_values = trained_net.forward(vol3d);
        console.log("predicted values: %o", predicted_values);
    }
}

if (!PREDICTIONS_ENABLED) {
    console.log("Error: predictions are disabled! Set PREDICTIONS_ENABLED flag to true.");
    
} else {
    // Evaluate arguments.
    var image_path;
    var text;
    var font;
    var font_size;
    var pos_x;
    var pos_y;
    var H1, S1, B1, H2, S2, B2, H3, S3, B3;

    process.argv.forEach(function (val, index, array) {
        if (index > 1) {
            eval(val);
        }
    });
    
    // Run Octave script to obtain the H, S and B of three dominant colors.
    var dominant_colors_process = 'octave -q --eval "dominant_color ' + image_path + ' ' + text + ' ' + font + ' ' + font_size + ' ' + pos_x + ' ' + pos_y + '" 2> /dev/null';
    exec(dominant_colors_process, function callback(error, stdout, stderr) {
         var words = stdout.split(/\n|\r| /);
         H1 = words[0];
         S1 = words[1];
         B1 = words[2];
         H2 = words[3];
         S2 = words[4];
         B2 = words[5];
         H3 = words[6];
         S3 = words[7];
         B3 = words[8];
         
         // Create input data.
         var vol3d = new convnetjs.Vol(3, 1, 3);
         
         vol3d.set(0, 0, 0, 360 * H1);
         vol3d.set(0, 0, 1, 100 * S1);
         vol3d.set(0, 0, 2, 100 * B1);
         vol3d.set(1, 0, 0, 360 * H2);
         vol3d.set(1, 0, 1, 100 * S2);
         vol3d.set(1, 0, 2, 100 * B2);
         vol3d.set(2, 0, 0, 360 * H3);
         vol3d.set(2, 0, 1, 100 * S3);
         vol3d.set(2, 0, 2, 100 * B3);
         
         // Predict.
         var predicted_value = trained_net.forward(vol3d);
         var predicted_H = Math.min(360, Math.max(0, predicted_value.w[0])) / 360;
         var predicted_S = Math.min(360, Math.max(0, predicted_value.w[1])) / 100;
         var predicted_B = Math.min(360, Math.max(0, predicted_value.w[2])) / 100;
         
         // console.log("predicted value: H: %d, S: %d, B: %d", predicted_H, predicted_S, predicted_B);
         
         // Call the script which put the text onto the image.
         var write_text_process = 'octave -q --eval "write_color_image ' + image_path + ' ' + text + ' ' + font + ' ' + font_size + ' ' + pos_x + ' ' + pos_y + ' '
                                   + predicted_H + ' ' + predicted_S + ' ' + predicted_B + '" 2> /dev/null';
         exec(write_text_process, function callback(error, stdout, stderr) {
         });
    });
}
